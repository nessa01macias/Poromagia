{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Exacting text from a card "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2 is the module import name for opencv-python needed for the cv algorithm\n",
    "import cv2\n",
    "# pillow is needed to editing images, printing them, rotating them...\n",
    "from PIL import Image\n",
    "#exact text from images using pytesseract\n",
    "import pytesseract \n",
    "#basic path works for all the files\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading an image with opencv. They become a bunch of numbers in a array that refer to [r,g,b] which means \"per pixel\" how much color of each is used. in order to display an array, we use pillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[199, 194, 203],\n",
       "        [203, 198, 207],\n",
       "        [208, 205, 214],\n",
       "        ...,\n",
       "        [208, 218, 228],\n",
       "        [208, 218, 228],\n",
       "        [208, 218, 228]],\n",
       "\n",
       "       [[195, 190, 199],\n",
       "        [195, 190, 199],\n",
       "        [195, 192, 201],\n",
       "        ...,\n",
       "        [208, 218, 228],\n",
       "        [208, 218, 228],\n",
       "        [208, 218, 228]],\n",
       "\n",
       "       [[195, 191, 197],\n",
       "        [191, 187, 193],\n",
       "        [184, 181, 190],\n",
       "        ...,\n",
       "        [208, 218, 228],\n",
       "        [208, 218, 228],\n",
       "        [208, 218, 228]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 98, 148, 200],\n",
       "        [ 98, 148, 200],\n",
       "        [ 97, 147, 199],\n",
       "        ...,\n",
       "        [181, 200, 221],\n",
       "        [181, 200, 221],\n",
       "        [181, 200, 221]],\n",
       "\n",
       "       [[ 98, 148, 200],\n",
       "        [ 98, 148, 200],\n",
       "        [ 97, 147, 199],\n",
       "        ...,\n",
       "        [181, 200, 221],\n",
       "        [181, 200, 221],\n",
       "        [181, 200, 221]],\n",
       "\n",
       "       [[ 98, 148, 200],\n",
       "        [ 97, 147, 199],\n",
       "        [ 97, 147, 199],\n",
       "        ...,\n",
       "        [181, 200, 221],\n",
       "        [181, 200, 221],\n",
       "        [181, 200, 221]]], dtype=uint8)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original image, we could even apply a '0' as a parameter to make it black & white\n",
    "image = cv2.imread(\"resourcesTesting/card-01.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image from Pillow makes the pic printable as a image and not only an array\n",
    "Image.fromarray(image).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Binarization. Images will have different shadings and we would like all of them to be as similar to each other as possible, therefore threshold is needed. If we didn't use the contract, probably the text extraction would not be even half of efficient as it can be after applying the threshold. [check out doc!]\n",
    "(https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)\n",
    "\n",
    "The best way is to turn the image black & white, and then apply threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale (image):\n",
    "    #cv2.COLOR_BGR2GRAY converts an image to grey\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image = grayscale(image)\n",
    "# check the new black & white image \n",
    "Image.fromarray(gray_image).show()\n",
    "\n",
    "\n",
    "\n",
    "# imwrite saves an image which we dont need to do, it just allows testing\n",
    "imag_path = sys.path[0]+\"/temp/card-01-grey.jpg\"\n",
    "cv2.imwrite(imag_path,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the threshold: chose thresh_binary because we want each pixel to be either white or black. \n",
    "# Also, we need them to be baclk & white as it is easier in pytesseract to work with them\n",
    "thresh, gray_thresh_image = cv2.threshold(gray_image,150, 255,cv2.THRESH_BINARY)\n",
    "Image.fromarray(gray_thresh_image).show() # i can also use Image.fromarray(sys.path[0]+\"/temp/card-01-grey-thresh.jpg\").show()\n",
    "\n",
    "\n",
    "# imwrite saves an image which we dont need to do, it just allows testing\n",
    "imag_path = sys.path[0]+\"/temp/card-01-grey-thresh.jpg\"\n",
    "cv2.imwrite(imag_path,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ROI. Region of interest. We need to separate the [card name], [card image] and [card type] from the picture before extracting the text. The previous steps work for the text extraction, as the image extraction needs other kind of preprocessing before \"cutting\" the image in the region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extracting the text from [card type] & [card name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/pytesseract/ has important documentation about pytesseract, including the modes of data extraction\n",
    "custom_oem_psm_config = r'--oem 3 --psm 3' # OEM 3 PSM 3 is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Enchantment\n",
      "\n",
      "Landfall — Whenever a land enters\n",
      "\n",
      "the battlefield under your control,\n",
      "\n",
      "choose one —\n",
      "\n",
      "*Put a +1/+1 counter on target\n",
      "creature.\n",
      "\n",
      "* You gain 2 life.\n",
      "\n",
      "078 U IM 6 2020 Wizards of the Coast\n",
      "ZNC + EN Me KINRAN YANNER\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying to extract text after a bit of pre-processing \n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "text = pytesseract.image_to_string(gray_thresh_image, lang=\"eng\",config=custom_oem_psm_config)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0b219ec83649936bce7717ffc92d24e05b7358d200d73bcdb3e34c55ccc427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
