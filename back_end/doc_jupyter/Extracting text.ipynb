{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Exacting text from a card "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something extremetly important to take into consideration is the fact that as we will use regions of interest for image extractions, the picture of the cards need to be taken in **exactly** the same angle and the same coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2 is the module import name for opencv-python needed for the cv algorithm\n",
    "import cv2\n",
    "# pillow is needed to editing images, printing them, rotating them...\n",
    "from PIL import Image\n",
    "#exact text from images using pytesseract\n",
    "import pytesseract \n",
    "#basic path works for all the files\n",
    "import sys\n",
    "#array handling\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is something to look into when someone else uses the code!!!! they need to install pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading an image with opencv. They become a bunch of numbers in a array that refer to [r,g,b] which means \"per pixel\" how much color of each is used. in order to display an array, we use pillow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[233, 217, 200],\n",
       "        [233, 217, 200],\n",
       "        [233, 217, 200],\n",
       "        ...,\n",
       "        [167, 170, 168],\n",
       "        [170, 173, 171],\n",
       "        [173, 176, 174]],\n",
       "\n",
       "       [[236, 220, 203],\n",
       "        [236, 220, 203],\n",
       "        [237, 221, 204],\n",
       "        ...,\n",
       "        [167, 170, 168],\n",
       "        [171, 174, 172],\n",
       "        [174, 177, 175]],\n",
       "\n",
       "       [[230, 214, 197],\n",
       "        [230, 214, 197],\n",
       "        [230, 214, 197],\n",
       "        ...,\n",
       "        [168, 171, 169],\n",
       "        [172, 175, 173],\n",
       "        [176, 179, 177]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[167, 191, 209],\n",
       "        [167, 191, 209],\n",
       "        [167, 191, 209],\n",
       "        ...,\n",
       "        [170, 200, 225],\n",
       "        [170, 200, 225],\n",
       "        [170, 200, 225]],\n",
       "\n",
       "       [[166, 190, 208],\n",
       "        [167, 191, 209],\n",
       "        [168, 192, 210],\n",
       "        ...,\n",
       "        [170, 200, 225],\n",
       "        [170, 200, 225],\n",
       "        [170, 200, 225]],\n",
       "\n",
       "       [[165, 189, 207],\n",
       "        [168, 192, 210],\n",
       "        [169, 193, 211],\n",
       "        ...,\n",
       "        [170, 200, 225],\n",
       "        [170, 200, 225],\n",
       "        [170, 200, 225]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original image, we could even apply a '0' as a parameter to make it black & white\n",
    "image = cv2.imread(\"1.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Image from Pillow makes the pic printable as a image and not only an array\n",
    "Image.fromarray(image).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Binarization. Images will have different shadings and we would like all of them to be as similar to each other as possible, therefore threshold is needed. If we didn't use the contract, probably the text extraction would not be even half of efficient as it can be after applying the threshold. [check out doc!]\n",
    "(https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html)\n",
    "\n",
    "The best way is to turn the image black & white, and then apply threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale (image):\n",
    "    #cv2.COLOR_BGR2GRAY converts an image to grey\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image = grayscale(image)\n",
    "# check the new black & white image \n",
    "Image.fromarray(gray_image).show()\n",
    "\n",
    "# imwrite saves an image which we dont need to do, it just allows testing\n",
    "imag_path = sys.path[0]+\"/temp/card-02-grey.jpg\"\n",
    "cv2.imwrite(imag_path,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[214, 214, 214, ..., 169, 172, 175],\n",
       "       [217, 217, 218, ..., 169, 173, 176],\n",
       "       [211, 211, 211, ..., 170, 174, 178],\n",
       "       ...,\n",
       "       [194, 194, 194, ..., 204, 204, 204],\n",
       "       [193, 194, 195, ..., 204, 204, 204],\n",
       "       [192, 195, 196, ..., 204, 204, 204]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the image, as it is black & white it only has one element per pixel. pixel is inside the range of 0 (completely black) to 255 (completely white)\n",
    "gray_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the threshold: chose thresh_binary because we want each pixel to be either white or black. \n",
    "# Also, we need them to be baclk & white as it is easier in pytesseract to work with them\n",
    "thresh, gray_thresh_image = cv2.threshold(gray_image,130, 255,cv2.THRESH_BINARY)\n",
    "Image.fromarray(gray_thresh_image).show() # i can also use Image.fromarray(sys.path[0]+\"/temp/card-01-grey-thresh.jpg\").show()\n",
    "\n",
    "\n",
    "# imwrite saves an image which we dont need to do, it just allows testing\n",
    "imag_path = sys.path[0]+\"/temp/card-02-grey-thresh.jpg\"\n",
    "cv2.imwrite(imag_path,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_thresh_image = np.asarray(gray_thresh_image)\n",
    "\n",
    "gray_thresh_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ROI. Region of interest. We need to separate the [card name], [card image] and [card type] from the picture before extracting the text. The previous steps work for the text extraction, as the image extraction needs other kind of preprocessing before \"cutting\" the image in the region of interest.\n",
    "Something really important to take into consideration is that all the cards must be in the same position, and the same angle everytime the picture is taken to avoid more pre-processing and make the ROI more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows  1536  and columns  2048\n"
     ]
    }
   ],
   "source": [
    "num_rows, num_cols = gray_thresh_image.shape\n",
    "print(\"number of rows \",num_rows, \" and columns \",num_cols)\n",
    "# the number of rows and columns are really important for the following part-extrations of the images. they will be changing as the proper\n",
    "#values from the arduino come to the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [row, columns]\n",
    "rows_cardName = [350, 1250]\n",
    "columns_cardName = [310, 400]\n",
    "image_ROI_cardName = gray_thresh_image[rows_cardName[0]:rows_cardName[1], columns_cardName[0]:columns_cardName[1]]\n",
    "# now image_ROI_carName contains the cardName from each card\n",
    "Image.fromarray(image_ROI_cardName).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [row, columns]\n",
    "rows_cardType = [350, 1250]\n",
    "columns_cardType = [1050, 1150]\n",
    "\n",
    "image_ROI_cardType = gray_thresh_image[rows_cardType[0]:rows_cardType[1], columns_cardType[0]:columns_cardType[1]]\n",
    "# now image_ROI_carName contains the cardName from each card\n",
    "# Image.fromarray(image_ROI_cardType).show()\n",
    "Image.fromarray(cv2.rotate(image_ROI_cardType,cv2.ROTATE_90_CLOCKWISE)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extracting the text from [card type] & [card name]. The regions of interest have been identified and we will try to extract text from them. The best way is to make a function that is called every time we need extraction. # https://pypi.org/project/pytesseract/ has important documentation about pytesseract, including the modes of data extraction, and in this case OEM 3 PSM 3 is pretty good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text (rows, columns) -> str:\n",
    "   # print(rows[0],rows[1])\n",
    "   # print(columns[0], columns[1])\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 3'\n",
    "    # first we implement the region cuttting \n",
    "    ROI_image =  gray_thresh_image[rows[0]:rows[1], columns[0]:columns[1]]\n",
    "    # then we rotate the image\n",
    "    ROI_image = cv2.rotate(ROI_image,cv2.ROTATE_90_CLOCKWISE)\n",
    "    # showing it just for testing \n",
    "    Image.fromarray(ROI_image).show()\n",
    "    # and we extract the text from it\n",
    "    text = pytesseract.image_to_string(ROI_image, lang=\"eng\",config=custom_oem_psm_config)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need string library to include all ASCII letters\n",
    "import string \n",
    "\n",
    "def clean_text(text:str) -> str:\n",
    "    # ascii_letters include all the letters from english alphabet in lower and upper case\n",
    "    included = string.ascii_letters\n",
    "    # first we treat the text as an array because strings are inmutable in python\n",
    "    new_str = []\n",
    "    for char in text: #h, #o, #l, #a, #!\n",
    "        if char in included or char == ' ' or char == '—':\n",
    "            # appeding to the array if the string is included\n",
    "            new_str.append(char)\n",
    "    # removing extra spaces\n",
    "    new_text = ''.join(new_str)\n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the text from the top part (card name) is Lightning Strike  and from the middle part (card type) is Instant\n"
     ]
    }
   ],
   "source": [
    "text_cardName = clean_text(extract_text(rows_cardName, columns_cardName))\n",
    "text_cardType = clean_text(extract_text(rows_cardType, columns_cardType))\n",
    "print(\"the text from the top part (card name) is\", text_cardName , \" and from the middle part (card type) is\", text_cardType)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0b219ec83649936bce7717ffc92d24e05b7358d200d73bcdb3e34c55ccc427"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
